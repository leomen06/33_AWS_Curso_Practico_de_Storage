{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e016c62",
   "metadata": {},
   "source": [
    "## <a name=\"index\"></a> Indice\n",
    "\n",
    "[Proyecto de arquitectura e implementación de almacenamiento](#mark_01)\n",
    "\n",
    "[Características de S3](#mark_02)\n",
    "\n",
    "[Versionamiento de archivos en S3](#mark_03)\n",
    "\n",
    "[Sitio web estático](#mark_04)\n",
    "\n",
    "[Logs a nivel de objetos en S3](#mark_05)\n",
    "\n",
    "[Transferencia acelerada](#mark_06)\n",
    "\n",
    "[Eventos en S3](#mark_07)\n",
    "\n",
    "[Replicación](#mark_08)\n",
    "\n",
    "[Tipos de Storages S3-Standard](#mark_09)\n",
    "\n",
    "[Tipos de Storages S3-IA](#mark_10)\n",
    "\n",
    "[Tipos de Storages S3-IA única zona](#mark_11)\n",
    "\n",
    "[Tipos de Storages Glacier](#mark_12)\n",
    "\n",
    "[Ciclo de vida en S3](#mark_13)\n",
    "\n",
    "[Estrategias de migración a la nube](#mark_14)\n",
    "\n",
    "<a name=\"index_01\"><a/>\n",
    "\n",
    "[Casos de uso  \"S3\" - **Big Data**](#mark_15)\n",
    "\n",
    "[Casos de uso  \"S3\" - **Compliance**](#mark_16)\n",
    "\n",
    "[Encriptación en S3 - Llaves administradas por AWS](#mark_17)\n",
    "\n",
    "[Encriptación en S3 - Llaves almacenadas en AWS creadas por el Usuario (KMS).](#mark_18)\n",
    "\n",
    "[Encriptación en S3 - Llaves del Usuario - \"SSE-C\"](#mark_19)\n",
    "\n",
    "[Laboratorio- crear llaves KMS y encriptación de objetos en S3](#mark_20)\n",
    "\n",
    "[Encriptación Python lib Boto 3](#mark_21)\n",
    "\n",
    "[Introducción a Políticas en S3](#mark_22)\n",
    "\n",
    "[Ejemplos de Políticas en S3](#mark_23)\n",
    "\n",
    "[ACL (Access Control List) en S3](#mark_24)\n",
    "\n",
    "[Storage Gateway](#mark_25)\n",
    "\n",
    "[File Gateway](#mark_26)\n",
    "\n",
    "[VTL - Virtual Tape Library Tape Gateway](#mark_27)\n",
    "\n",
    "[Volume Gateway](#mark_28)\n",
    "\n",
    "[Elastic File System](#mark_29)\n",
    "    \n",
    "<a name=\"index_02\"></a>\n",
    "\n",
    "[Casos de uso de EFS](#mark_30)\n",
    "\n",
    "[Características de Elastic Block Storage](#mark_31)\n",
    "\n",
    "[Tipos de EBS - GP2 - IO1](#mark_32)\n",
    "\n",
    "[Tipos de EBS - ST1 - SC1](#mark_33)\n",
    "\n",
    "[Snapshots y AMI](#mark_34)\n",
    "\n",
    "[Creación de EBS + integración con EC2 para Windows](#mark_35)\n",
    "    \n",
    "[Creación de EBS + integración con EC2 para Linux](#mark_36)\n",
    "    \n",
    "[AWS Storage \"S3\" vs \"EBS\" vs \"EFS\", Cuándo usar cada uno](#mark_37)\n",
    "    \n",
    "[](#mark_)\n",
    "    \n",
    "[](#mark_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6440e1df",
   "metadata": {},
   "source": [
    "## <a name=\"mark_01\"></a> Proyecto de arquitectura e implementación de almacenamiento\n",
    "\n",
    "## [Indice](#index)\n",
    "\n",
    "\n",
    "Como proyecto de este curso vas a hacer de cuenta que eres el arquitecto de soluciones de una empresa y el CEO te ha pedido diseñar una arquitectura de almacenamiento para la empresa de seguros. Además, debes implementar una prueba de concepto que como mínimo cuente con lo siguiente:\n",
    "\n",
    "- 2 buckets en diferentes regiones.\n",
    "\n",
    "- Replicación de archivos entre las regiones.\n",
    "\n",
    "- Pruebas de replicación entre regiones.\n",
    "\n",
    "- Configuración del bucket principal con las siguientes funcionalidades:\n",
    "\n",
    "    - Versionamento.\n",
    "    \n",
    "    - Encriptación con KMS.\n",
    "    \n",
    "Ciclo de vida de la siguiente forma (no para objetos versiones anteriores):\n",
    "\n",
    "1. Objetos mayores a 2 meses pasan a S3-IA.\n",
    "\n",
    "2. Objetos con 6 meses de antigüedad pasan a Glacier.\n",
    "\n",
    "3. Objetos con 2 años de antigüedad deben borrarse.\n",
    "\n",
    "- Crear un servidor con un volumen EBS agregado a la instancia.\n",
    "\n",
    "- A través de la CLI consultar los buckets generados y migrar la información que se tiene en el EBS al bucket usando la CLI.\n",
    "\n",
    "- Genera un snapshot del volumen y mígralo a la región en donde se encuentra el bucket secundario.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4420529e",
   "metadata": {},
   "source": [
    "## <a name=\"mark_02\"></a> Características de S3\n",
    "\n",
    "## [Indice](#index)\n",
    "\n",
    "![](img_01.png)\n",
    "\n",
    "Objetos --> Archivos, pdf, imagenes, documentos, hojas de calculo, o cualquier tipo de archivo. Podemos hacer una similitud que el almacenamiento por objetos es como un Dropbox (de hecho Dropbox está contruido con un S3)\n",
    "\n",
    "Dentro de S3 contamos con diferentes tipos de storages:\n",
    "\n",
    "_ S3 Standard\n",
    "\n",
    "_ S3 IA (Infrecuently Access, acceso poco frecuente)\n",
    "\n",
    "_ S3 IA One Zone (acceso poco frecuente de una zona)\n",
    "\n",
    "_ Glacier\n",
    "\n",
    "Dependiendo de la clase de S3 va a variar la durabilidad y disponibilidad.\n",
    "\n",
    "Bucket es la unidad donde vamos a almacenar la información en S3, su identificador/dirección se encuentra compuesto por la **región donde fue creado**, la dirección de **Amazon AWS** y el **nombre del bucket**. Para los casos cuando queramos acceder a un objeto simplemente se le suma el nombre del objeto, este debe ser único, en minúsculas y no se permiten los caracteres especiales salvo _ y -. El nombre de un Bucket debe ser único a nivel global.\n",
    "\n",
    "Tener en cuenta que para los buckets creados en la region de **Virginia**, puede no aparecer la \"región\", debido a que Virgina es la zona por defecto para AWS.\n",
    "\n",
    "![](img_02.png)\n",
    "\n",
    "S3 es un servicio Global, no depende de una región, para que pueda ser visto si trabajamos de cualquier otra región.\n",
    "\n",
    "A pesar de que S3 es un servicio Global, hay ciertos proyectos donde es necesario que el Bucket se encuentre en la misma región de la infraestructura que despleguemos. Esto es debido a que en ciertos proyectos la latencia es una variable muy importante, por lo tanto en este tipo de proyectos debemos desplegar nuestros objetos lo más cerca de nuestra infraestructura.\n",
    "\n",
    "En el momento en que generamos WEB Estáticas, también generamos como un link una url a esta web estática, en la imagen anterios se puede observar la diferencia entre las url de los bucket y objetos a las url de las web estáticas.\n",
    "\n",
    "### Diferencia entre web estática y dinámica\n",
    "\n",
    "La diferencia fundamental entre una web estática y una web dinámica es que la web estática no cambia su contenido, mientras que la web dinámica sí.\n",
    "\n",
    "**Web estática**\n",
    "\n",
    "Una web estática es una página web que se genera a partir de archivos HTML, CSS y JavaScript estáticos. Estos archivos se almacenan en el servidor web y se envían al navegador del usuario sin necesidad de realizar ningún procesamiento adicional.\n",
    "\n",
    "Las webs estáticas son sencillas de crear y mantener, ya que no requieren conocimientos de programación. Sin embargo, también son limitadas en cuanto a las posibilidades de interacción con el usuario y la personalización.\n",
    "\n",
    "**Web dinámica**\n",
    "\n",
    "Una web dinámica es una página web que se genera a partir de datos que se almacenan en una base de datos. Estos datos pueden ser texto, imágenes, videos o cualquier otro tipo de información.\n",
    "\n",
    "La web dinámica se genera en el servidor web, en función de la interacción del usuario con la página. Por ejemplo, una web dinámica puede mostrar una lista de productos que se ajusten a los criterios de búsqueda del usuario.\n",
    "\n",
    "Las webs dinámicas son más complejas que las webs estáticas, pero ofrecen una mayor flexibilidad y posibilidades de interacción con el usuario.\n",
    "\n",
    "**Tabla comparativa**\n",
    "\n",
    "| Característica | Web estática | Web dinámica |\n",
    "|---|---|---|\n",
    "| Contenido | Fijo | Variable |\n",
    "| Creación | Sencilla | Compleja |\n",
    "| Mantenimiento | Fácil | Difícil |\n",
    "| Interacción con el usuario | Limitada | Amplia |\n",
    "| Personalización | Limitada | Amplia |\n",
    "\n",
    "**Ejemplos**\n",
    "\n",
    "* **Web estática:** Una página web de una empresa que presenta sus productos y servicios.\n",
    "* **Web dinámica:** Una página web de comercio electrónico que permite a los usuarios realizar compras.\n",
    "* **Web estática:** Una página web de noticias que presenta los últimos titulares.\n",
    "* **Web dinámica:** Una página web de encuestas que permite a los usuarios votar sobre diferentes temas.\n",
    "\n",
    "**Elección de la tecnología adecuada**\n",
    "\n",
    "La elección de la tecnología adecuada para crear una web depende de las necesidades específicas del proyecto. Si se necesita una web sencilla y fácil de mantener, una web estática puede ser una buena opción. Sin embargo, si se necesita una web con una mayor interacción con el usuario y posibilidades de personalización, una web dinámica puede ser una mejor opción."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a086e3",
   "metadata": {},
   "source": [
    "## <a name=\"mark_03\"></a> Versionamiento de archivos en S3\n",
    "\n",
    "## [Indice](#index)\n",
    "\n",
    "Tener un control de versiones de tus archivos es importante y necesario cuando manejamos información muy delicada. En los casos donde tenemos un error o cargamos un archivo incompleto siempre podremos volver a la versión anterior de nuestro archivo.\n",
    "\n",
    "Al momento de ir añadiendo varias versiones de un archivo AWS va a poner un tag al último archivo para tener claro que es esta la última versión. \n",
    "\n",
    "## Es importante!!! tener en cuenta que la característica de versionamiento cobra por el almacenamiento total de tus archivos, es decir la última versión y todas sus versiones anteriores.\n",
    "\n",
    "Para este ejemplo vamos a crear un Bucket (recordar que el nombre debe ser único).\n",
    "\n",
    "![](img_03.png)\n",
    "\n",
    "![](img_04.png)\n",
    "\n",
    "![](img_05.png)\n",
    "\n",
    "Abrimos el bucket, y vamos a propiedades, para activar la funcionalidad de \"Versioning\".\n",
    "\n",
    "![](img_06.png)\n",
    "\n",
    "![](img_07.png)\n",
    "\n",
    "![](img_08.png)\n",
    "\n",
    "Luego creamos en nuestro local, por ejemplo un \"archivo1.txt\", simplemente para ir modificandolo y experimentando el cambio de versiones.\n",
    "\n",
    "1. Cargamos por primera vez ese archivo en el bucket creado\n",
    "\n",
    "2. Generamos una 1er modificación en nuestro local sobre el archivo1.txt, y volvemos cargarlo en el bucket (como sobre-escribiendo la última versión)\n",
    "\n",
    "3. Generamos una 2da modificación en nuestro local sobre el archivo1.txt, y volvemos cargarlo en el bucket (como sobre-escribiendo la última versión)\n",
    "\n",
    "Como el versionamiento agrega un tag al archivo a medida que se modifica y lo oculta debemos indicarle que muestre los cambios.\n",
    "\n",
    "![](img_09.png)\n",
    "\n",
    "![](img_10.png)\n",
    "\n",
    "![](img_11.png)\n",
    "\n",
    "Si necesitamos alguna de esas versiones simplemente hacemos click sobre ella y la descargamos.\n",
    "\n",
    "\n",
    "\n",
    "Lectura recomendada:\n",
    "\n",
    "https://docs.aws.amazon.com/es_es/AmazonS3/latest/dev/Versioning.html\n",
    "\n",
    "Calculador de costos:\n",
    "\n",
    "https://calculator.aws/#/?key=new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d529da",
   "metadata": {},
   "source": [
    "## <a name=\"mark_04\"></a> Sitio web estático\n",
    "\n",
    "## [Indice](#index)\n",
    "\n",
    "Podremos utilizar nuestro propio dominio como en cualquier sitio web estático, para ello usaremos Route 53 que es el servicio encargado de la parte de DNS y gestión de dominios en S3.\n",
    "\n",
    "En los sitios web estáticos debes tener en cuenta que el dominio deberá llamarse igual al bucket, los archivos index y error deben ser públicos, y debe ser configurado con el servicio Route 53.\n",
    "\n",
    "Características de integración con Route 53:\n",
    "\n",
    "    _ Redireccionamiento de tráfico.\n",
    "    _ Puede funcionar como un sitio web estático normal.\n",
    "    _ Podemos integrarlo con el servicio de Cloud Front, para temas de cache de contenido\n",
    "    \n",
    "Caracaterísticas a tener en cuenta en sitio web estáticos.\n",
    "\n",
    "![](img_12.png)\n",
    "\n",
    "El dominio debe llamarse igual al buckert:\n",
    "\n",
    "    _ Nombre del dominio \"www.abc123.com\"\n",
    "    \n",
    "    _ Nombre del bucket \"www.abc123.com\"\n",
    "    \n",
    "## Precuación si primero creamos nuestro dominio estático y en un segundo paso intentamos crear el bucker con el mismo nombre, (pero nombre del bucket ya está siendo utilizado por otro usuario), entonce no podremos crearlo y por lo tanto tampoco podremos conectar nuestro sitio estático, ya que los nombres deben coincidir.\n",
    "\n",
    "Cuando creemos el sitio web estático va a pedir 2 tipos de archivos.\n",
    "\n",
    "    1. Cual va a ser nuestro index.html o la página a la cual vamos a apuntar el sitio web estático.\n",
    "    \n",
    "    2. Y si la primer opción falla no pedirá una segunda página de \"error.html\"\n",
    "\n",
    "Para realizar estás acciones debemos integrar con Route 53, si queremos que nuestro dominio personalizado funcione para ver la información de un sitio web estático en S3.\n",
    "\n",
    "## Configuración en S3:\n",
    "\n",
    "Nos posicionamos en nuestro bucket, para este ejemplo \"dopscloud.click\" --> vamos a propieades --> Buscamos \"Static Website Hosting\"\n",
    "\n",
    "![](img_13.png)\n",
    "\n",
    "Parados en \"Static Website Hosting\", podemos observar el endpoint con la estructura de nuestro sitio web stático.\n",
    "\n",
    "_ vamos a utilizar este bucket para almacenar nuestro sitio web estático, lo seteamos de la siguiente forma y salvamos.\n",
    "\n",
    "![](img_14.png)\n",
    "\n",
    "Como vemos a continuación la funcionalidad de Servicio Web Estático ya se encuentra activada.\n",
    "\n",
    "![](img_15.png)\n",
    "\n",
    "## index.html y error.html\n",
    "\n",
    "1. Creamos nuestros archivos index.html y error.html, para esto simplemente se crearon en un notepad con los textos \"Este es nuestro INDEX\" y \"este es nuestro archivo de ERROR\" y ponemos los nombre correspondientes a cada archivo.\n",
    "\n",
    "2. Cargamos los archivos index.html y error.html dentro del bucket.\n",
    "\n",
    "![](img_16.png)\n",
    "\n",
    "3. hacemos doble click sobre \"index.html\" y activamos \"Make public\"\n",
    "\n",
    "![](img_17.png)\n",
    "\n",
    "4. luego de esto ya estamos habilitados, copiando el endpoint mostrado anteriormente y pegandolo en un navegador ya podremos ver el contenido.\n",
    "\n",
    "![](img_18.png)\n",
    "\n",
    "El mismmo procedimiento debemos realizar con el archivo de error.html. Pero como probamos que el archivo de error fucione correctamente?. Muy sencillo, borramos el archivo \"index.html\" esto generará un error al intentar buscarlo y nos redireccionará a error.html\n",
    "\n",
    "![](img_19.png)\n",
    "\n",
    "## Como conectamos con un dominio ya existente?\n",
    "\n",
    "Como ya indicamos Route 53 es el servicio que maneja las DNS, el dominio **debe ser comprado** en el panel izquierdo **Registered domains** \n",
    "\n",
    "![](img_20.png)\n",
    "\n",
    "Hacemos click sobre el dominio para ver el dashboard, siempre que creamos un dominio nos crea dos tipos de registros, que no se deben tocar, \"NS\" y \"SOA\".\n",
    "\n",
    "![](img_21.png)\n",
    "\n",
    "Luego creamos un record set --> click \"Create record set\", un record set es un registro nuevo. Al seleccionar el alias se habilita el drop down de \"Alias Target\", en esta parte Route 53 detecta los buckets que se llaman exactamente igual a nuestro dominio y los muestra, (solo si tienen el Web Stating Hosting habilitado), lo seleccionamos y generamos la asociación, click en \"Create\"\n",
    "\n",
    "![](img_22.png)\n",
    "\n",
    "Se crea un nuevo registro para este ejemplo \"A\", que va desde el nombre del dominio, detecta que el bucket se llamen igual, y hace la redirección del tráfico (como es un cambio de DNS no es completamente inmediato).\n",
    "\n",
    "![](img_23.png)\n",
    "\n",
    "Luego de esto podemos utilizar solamente el nombre del dominio para acceder a index.htm\n",
    "\n",
    "![](img_24.png)\n",
    "\n",
    "Algunos casos de uso:\n",
    "\n",
    "1. Reporte html generados a travéz de pipelines y automatizaciones, orquestando un pipeline completo y guardando el reporte en el bucket, con lo cual garantizamos que al ingresar a nuestro dominio siempre vamos a ver los últimos reportes.\n",
    "\n",
    "2. Pipelines para test de celulares sobre device farm --> reporte creado al final de pipeline copiado a S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5586c417",
   "metadata": {},
   "source": [
    "## <a name=\"mark_05\"></a> Logs a nivel de objetos en S3\n",
    "\n",
    "## [Indice](#index)\n",
    "\n",
    "Supongamos tener información sencible en un determinado bucket, con lo cual deseamos saber quienes están intentado acceder o accediendo al bucket y que acciones están ejecutando sobre la información.\n",
    "\n",
    "Podemos activar el Object-level Logging dentro de un bucket en S3 para llevar registro de todas las acciones que se realicen en este. Conocer que personas, roles, que usuarios están haciendo uso de nuestros objetos, esta funcionalidad nos sirve cuando tenemos buckets con información crítica. \n",
    "\n",
    "Al activar el Object-level Logging debemos conectarlo a CloudTrail, encargado de registrar todas las llamadas a la API. Como se muestra en la gráfica, podemos integrarlo con otros servicios más, llevar los logs de acciones sobre nuestro bucket crítio, que todas esas actividades queden registradas en Cloud Trail y finalmente guardar todas esas actividades en otro bucket final, o reemplazar este bucket final por CloudWatch, pudiendo realizar filtrados, crear alertas o integrarlo con algún otro servicio de AWS.\n",
    "\n",
    "![](img_25.png)\n",
    "\n",
    "Como funciona lo antes explicado.\n",
    "\n",
    "1. Buscamos el servicio y creamos el elemento Cloud Trail (Es una cola de registros donde se iran guardando las llamadas a la API de un servicio particular)\n",
    "\n",
    "![](img_29.png)\n",
    "\n",
    "![](img_30.png)\n",
    "\n",
    "![](img_31.png)\n",
    "\n",
    "![](img_32.png)\n",
    "\n",
    "Volvemso a S3 y podemos ver el bucket creado para almacenar los logs junto al bucket principal.\n",
    "\n",
    "![](img_33.png)\n",
    "\n",
    "Si ingresamos al bucket principal en la parte de properties buscamos \"Object-level loggin\" veremos ya se encuentra activa.\n",
    "\n",
    "![](img_34.png)\n",
    "\n",
    "Observación, si engresamos al bucket de logs, veremos que ya tiene una estructura de carpetas para comenzar a trabajar.\n",
    "\n",
    "![](img_35.png)\n",
    "\n",
    "Podemos descargar un json con los datos de esa/esas acciones.\n",
    "\n",
    "Una feature que podemos utilizar desde el punto de vista de seguridad:\n",
    "\n",
    "1. Hablilitamos Cloud Trial\n",
    "\n",
    "2. Habilitamos Objetc-Level logging en nuestros buckets críticos.\n",
    "\n",
    "3. Utilizando un sistema de notificaciones simple SNS, y las colas, se conectan a SOC, security operation center, para usar un dashboard de monitoreo de seguridad 24/7 \n",
    "\n",
    "4. Herramientas como splong tiene integración nativa con colas SQS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b645b768",
   "metadata": {},
   "source": [
    "## <a name=\"mark_06\"></a> Transferencia acelerada\n",
    "\n",
    "## [Indice](#index)\n",
    "\n",
    "Tomando ventaja del servicio de CDN (Servicio de Cache de Contenido) de AWS podemos cargar nuestra información a S3 de forma más rápida, esta característica no se encuentra disponible en buckets que contengan puntos (.) en su nombre.\n",
    "\n",
    "![](img_36.png)\n",
    "\n",
    "La transferencia acelerada te será sumamente útil cuando tengas que subir información a tu bucket, pero no te encuentres en la misma región donde creaste tu bucket.\n",
    "\n",
    "Ingresando al bucket, vamos a properties y buscamos \"Transefer acceleration\"\n",
    "\n",
    "![](img_37.png)\n",
    "\n",
    "![](img_38.png)\n",
    "\n",
    "Observar que nos brinda un endpoint especifico para este tipo de cargas\n",
    "\n",
    "También tenemos un enlace \"Want to compare your data transfer speed by regions\", esto nos mostrará cual es la región con mayor velocidad de transferencia (en ese momento) para que podamos hacer nuestra carga de datos lo más rápida posible desde cualquier parte del mundo.\n",
    "\n",
    "![](img_39.png)\n",
    "\n",
    "No tenemos que hacer nada más que activar la feature de accelerate, el sistema identifica la CDN con mejor performance para la carga de datos y la utiliza.\n",
    "\n",
    "Lectura recomendada:\n",
    "\n",
    "https://docs.aws.amazon.com/es_es/AmazonS3/latest/dev/transfer-acceleration.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c6cdeb",
   "metadata": {},
   "source": [
    "## <a name=\"mark_07\"></a> Eventos en S3\n",
    "\n",
    "## [Indice](#index)\n",
    "\n",
    "Los eventos nos servirán en los casos donde queremos recibir notificaciones cuando se ejecute determinada acción dentro de un bucket con información importante.\n",
    "\n",
    "Al momento de crear un evento debemos ponerle un nombre, indicarle la acción que debe notificar, además podemos especificarle la carpeta y el tipo de archivo. Por último, debemos indicarle hacia donde debe mandar la notificación:\n",
    "\n",
    "- SNS Topic (Sistema de Notificaciones Simple de AWS).\n",
    "\n",
    "- SQS Queue (Enviar a una cola).\n",
    "\n",
    "Lambda Function (Integraciones con otros servicios).\n",
    "\n",
    "Ingresamos a nuestro bucket --> properties --> Events\n",
    "\n",
    "![](img_40.png)\n",
    "\n",
    "Hacemos click en \"Add notification\"\n",
    "\n",
    "![](img_41.png)\n",
    "\n",
    "Tambien nos permite trazabilidad en nuestros eventos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8f9b59",
   "metadata": {},
   "source": [
    "## <a name=\"mark_08\"></a> Replicación\n",
    "\n",
    "## [Indice](#index)\n",
    "\n",
    "![](img_42.png)\n",
    "\n",
    "La característica de replicar información se realiza solamente para buckets de una región a otra, no es posible pasar de un bucket de una misma región a otro de la misma.\n",
    "\n",
    "El proceso de replicación se realiza de forma asíncrona. Es común realizar réplicas para Data Recovery, Auditorías y Compliance.\n",
    "\n",
    "Al momento de replicar la información podemos indicarle que sean todos los objetos del bucket, los objetos que se encuentren dentro de determinada carpeta o aquellos que tengan cierto tag. Además, podemos replicar objetos encriptados.\n",
    "\n",
    "# Cómo realizarlo en S3?:\n",
    "\n",
    "Ingresamos a nuestro bucket --> Management --> Replication --> + Add rule\n",
    "\n",
    "![](img_43.png)\n",
    "\n",
    "La replicación puede ser:\n",
    "\n",
    "    - Del total del bucket.\n",
    "    - De algún directorio especifico.\n",
    "    - Determinados tipos de objetos que tengan un \"tag\" (basicamente una metadata y un identificador del objeto).\n",
    "\n",
    "![](img_44.png)\n",
    "\n",
    "Replicación de objetos encriptados, un caso a tener en cuenta...\n",
    "\n",
    "Supongamos que tenemos dos cuentas A y B, A es nuestra cuenta y queremos compartir datos con la cuenta B que pertenece a un cliente, para poder realizar la replicación la cuenta B debe aceptar la replicación y esto implica que nuestro cliente debe conocer la llave de encriptación, con lo cual ahí tenemos un punto de seguridad muy importante para evaluar.\n",
    "\n",
    "![](img_45.png)\n",
    "\n",
    "Para este ejemplo, no elegimos la replicación encriptada.\n",
    "### Observación:\n",
    "`*************************************************************************************************************************`\n",
    "\n",
    "Si no seleccionas la opción \"Replicate objects encrypted with AWS KMS\" y los objetos en el bucket A están cifrados con AWS KMS, la replicación en el bucket B no mantendrá el cifrado original con AWS KMS y utilizará el cifrado predeterminado de Amazon S3 para el bucket B.\n",
    "\n",
    "`*************************************************************************************************************************`\n",
    "Pasamos al step 2 con Next.\n",
    "\n",
    "En este segundo paso, podemos replicar a otros buckets, de otras regiones que pertenezcan a nuestra cuenta, o podemos elegir buckets destino de otra cuenta.\n",
    "\n",
    "![](img_46.png)\n",
    "\n",
    "Para la elección del bucket de replica el sistema nos mostrará una lista de buckets, que no pertenecen a nuestra región.\n",
    "\n",
    "\n",
    "![](img_47.png)\n",
    "\n",
    "\n",
    "Una vez seleccionado el bucket, tenemos la opción \"Change de storage class\", esto nos permite que el bucket destino pueda ser, Standard, Standard-IA, etc. En definitiva podemos cambiar la clase del bucket destino.\n",
    "\n",
    "![](img_48.png)\n",
    "\n",
    "También el caso de que quieras cambiar el dueño del bucket esto es posible.\n",
    "\n",
    "![](img_49.png)\n",
    "\n",
    "Seleccionamos el role necesario para habilitar la replicación.\n",
    "\n",
    "![](img_50.png)\n",
    "\n",
    "Seleccionamos un nombre para la regla y la habilitamos, o no.\n",
    "\n",
    "![](img_51.png)\n",
    "\n",
    "## Actualización 2020:\n",
    "\n",
    "La replicación habilita la copia asincrónica y automática de los objetos entre buckets de Amazon S3. Los buckets que están configurados para replicación de objetos pueden pertenecer a la misma cuenta de AWS o a cuentas diferentes. Puede copiar objetos entre diferentes regiones de AWS o dentro de la misma región.\n",
    "\n",
    "Tipos de replicación de objetos Puede replicar objetos entre diferentes regiones de AWS o dentro de la misma región de AWS.\n",
    "\n",
    "Replicación entre regiones (CRR) se utiliza para copiar objetos entre buckets de Amazon S3 en diferentes regiones de AWS.\n",
    "\n",
    "Replicación en la misma región (SRR) se utiliza para copiar objetos entre buckets de Amazon S3 en la misma región de AWS.\n",
    "\n",
    "++Cuándo se debe usar CRR++ La replicación entre regiones puede ayudarle a hacer lo siguiente:\n",
    "\n",
    "Cumplir los requisitos de conformidad — Aunque Amazon S3 almacena sus datos en diversas zonas de disponibilidad alejadas geográficamente, de forma predeterminada los requisitos de conformidad pueden exigir que almacene los datos en ubicaciones aún más alejadas. La replicación entre regiones permite replicar los datos entre regiones de AWS alejadas para cumplir con estos requisitos de conformidad.\n",
    "\n",
    "Minimizar la latencia — Si sus clientes están en dos ubicaciones geográficas, puede minimizar la latencia en el acceso a los objetos manteniendo copias de los objetos en regiones de AWS que estén geográficamente más cerca de sus usuarios.\n",
    "\n",
    "Aumentar la eficiencia operativa — Si tiene clústeres informáticos en dos regiones diferentes de AWS que analizan el mismo conjunto de objetos, puede optar por mantener copias de objetos en dichas regiones.\n",
    "\n",
    "Fuente: https://docs.aws.amazon.com/es_es/AmazonS3/latest/dev/replication.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19844627",
   "metadata": {},
   "source": [
    "## <a name=\"mark_09\"></a> Tipos de Storages S3-Standard\n",
    "\n",
    "## [Indice](#index)\n",
    "\n",
    "\n",
    "![](img_52.png)\n",
    "\n",
    "SLA = Service Level Agreement. es una política que rige el uso de Amazon S3. Esos son los niveles de acuerdo de servicio. signifca que entre se llega a un acuerdo entre dos partes para dar soporte o respuesta a un servicio. ej: el SLA para solucion de incidentes es de 12 hrs, significa que el proveedor o el equipo de soporte tiene 12 hrs para responder al negocio o dar solucion. etc. son muy útiles para parametrizar los tiempos de respuesta de los equipos de soporte y que tu negocio tenga continuidad. Service Level Agreement. es puro servicio al cliente con métricas\n",
    "\n",
    "Zonas de disponibilidad: Zonas en las que nuestro información estará replicada por cuestiones de contigencia.\n",
    "\n",
    "N/D: No hay valor disponible.\n",
    "\n",
    "![](img_53.png)\n",
    "\n",
    "Lectura complementaria: https://aws.amazon.com/es/s3/storage-classes/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aa3cce",
   "metadata": {},
   "source": [
    "## <a name=\"mark_10\"></a> Tipos de Storages S3-IA\n",
    "\n",
    "## [Indice](#index)\n",
    "\n",
    "IA: Infrecuentlly Access\n",
    "\n",
    "Los objetos en S3-IA deben tener una taza de acceso menor a S3 Standard.\n",
    "\n",
    "![](img_54.png)\n",
    "\n",
    "Vamos a explicar \"Cargo mínimo de capacidad por objeto\" con un ejemplo, supongamos que necesitamos replicar o migrar un objeto desde un bucket hacia otro, este objeto debe tener un tamaño mínimo de 128 KB.\n",
    "\n",
    "![](img_55.png)\n",
    "\n",
    "Estos casos aplican cuando se accede a la información del bucket 1 o 2 veces al mes.\n",
    "\n",
    "Importante de 0 a 50 TB el precio es el que figura (para todos los S3), si almacenamos más de 50 TB el precio baja, en definitiva cuanta más información menor precio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5427cf",
   "metadata": {},
   "source": [
    "## <a name=\"mark_11\"></a> Tipos de Storages S3-IA única zona\n",
    "\n",
    "## [Indice](#index)\n",
    "\n",
    "Acceso poco frecuente replicado en una única zona\n",
    "\n",
    "![](img_56.png)\n",
    "\n",
    "![](img_57.png)\n",
    "\n",
    "Ejemplo de uso: Si la información guardada en este tipo de bucket no es crítica y puede ser regenerada desde otra fuente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaf0adc",
   "metadata": {},
   "source": [
    "## <a name=\"mark_12\"></a> Tipos de Storages Glacier\n",
    "\n",
    "## [Indice](#index)\n",
    "\n",
    "Back-up o Data Histórica.\n",
    "\n",
    "![](img_58.png)\n",
    "\n",
    "![](img_59.png)\n",
    "\n",
    "Características:\n",
    "\n",
    "    - Glacier Standar: de 3 a 5 horas para que la información este disponible.\n",
    "    \n",
    "    - Expedited : 1-5 minutos para para que la información este disponible.\n",
    "    \n",
    "    - Bulk: 5-12 horas para que la información este disponible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbccd48",
   "metadata": {},
   "source": [
    "## <a name=\"mark_13\"></a> Ciclo de vida en S3\n",
    "\n",
    "## [Indice](#index)\n",
    "\n",
    "![](img_60.png)\n",
    "\n",
    "## Configuración del ciclo de vida.\n",
    "\n",
    "Ingresamos al nuestro bucket, \"Management\" --> \"Lifecycle\" --> \"+ Add lifecycle rules\"\n",
    "\n",
    "![](img_61.png)\n",
    "\n",
    "Podemos limitar las reglas a Folders o Tags específicos.\n",
    "\n",
    "![](img_62.png)\n",
    "\n",
    "También nos permite configurar el ciclo de vida para \"el objeto actual\" y/o \"versiones previas\", a los cuales se les puede agregar diferentes ciclos \"+ add transition\".\n",
    "\n",
    "![](img_63.png)\n",
    "\n",
    "Ejemplo de transicionado.\n",
    "\n",
    "![](img_64.png)\n",
    "\n",
    "Expiración de objetos.\n",
    "\n",
    "![](img_65.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e56f3ee",
   "metadata": {},
   "source": [
    "## <a name=\"mark_14\"></a> Estrategias de migración a la nube\n",
    "\n",
    "## [Indice](#index)\n",
    "\n",
    "![](img_66.png)\n",
    "\n",
    "A petabyte (PB) is a unit of measurement in computers and similar electronic devices. One petabyte holds 1000 terabytes (TB) or 1,000,000,000,000,000 bytes.\n",
    "\n",
    "Cuando nosotros queremos migrar a S3 tenemos varias opciones.\n",
    "\n",
    "## Snowball \n",
    "\n",
    "Para migración de petabytes de información, es un dispositivo físico que debe enviarse a la oficina de quien lo solicita para llenarlo de datos y luego ser trasladado a las oficinas de Amazon, para su carga a S3 o el bucket elegido. La información debe ser resguardada y custodiada.\n",
    "\n",
    "Este servicio no está disponible en todos los países.\n",
    "\n",
    "![](img_67.png)\n",
    "\n",
    "Iniciamos la solicitud.\n",
    "\n",
    "![](img_68.png)\n",
    "\n",
    "Debemos ingresar los datos para el equipo sea enviado a nuestras oficinas.\n",
    "\n",
    "![](img_69.png)\n",
    "\n",
    "**Caso de uso**: Si en la empresa tenemos un canal de internet de 50Mbps, pero necesitamos migrar a la nuve 100 o 200 TB de información este canal no va a ser suficiente para migrar, para estos casos Snowball es una opción.  \n",
    "\n",
    "## Snowmobile\n",
    "\n",
    "Mover hexabyte de información.\n",
    "\n",
    "![](img_70.png)\n",
    "\n",
    "## Carga multiparte. \n",
    "\n",
    "Podemos dividir los archivos grandes en archivos mas pequeños a través de SDK o la CLI de AWS o Transferencia acelerada de objetos.\n",
    "\n",
    "Como se ve en el siguiente ejemplo, existe una limitación de tamaño por archivo (100Mb), por lo cual podemos dividir los archivos, subirlos en paralelo y volver a unificarlos una vez subidos. También tenemos la posibilidad de usar SDK con diferentes lenguajes. Y Finalmente utilizar la CLI de AWS para realizar una automatización directamente desde la shell.\n",
    "\n",
    "Limitaciones, al cargar objetos (método PUT) directamente a S3, como máximo suporta 5Gb por objeto, necesitaremos partir el objeto para cargarlo o utilizar otra estrategia.\n",
    "\n",
    "Un objeto en S3 tiene una limitación máxima de 5 TB\n",
    "\n",
    "![](img_71.png)\n",
    "\n",
    "Recordando...\n",
    "\n",
    "![](img_72.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37940555",
   "metadata": {},
   "source": [
    "## <a name=\"mark_15\"></a> Casos de uso  \"S3\" - **Big Data**\n",
    "\n",
    "## [Indice](#index_01)\n",
    "\n",
    "![](img_73.png)\n",
    "\n",
    "1. Tenemos una app que envía los logs a Cloudwatch registrando todas las acciones realizadas.\n",
    "\n",
    "2. Tarea en Ptyhon utilizando la SDK se conecta Cloudwatch, toma todos los logs del día anterior y los pasa a S3.\n",
    "\n",
    "3. S3 mantiene una estructura por días. Por ejemplo separando los logs por actividad realizada por el usuario \"año_mes_dia_accion\" (esta data debería estar encriptada)\n",
    "\n",
    "4. Cada noche se conecta al bucket EMR (Elastic Map Reduce) o AWS GLUE\n",
    "\n",
    "    - EMR crea un cluster basado en Hadoop el cual nos permite utilizar diferentes frameworks como Spark, Presto, etc para realizar procesamiento de información.\n",
    "    \n",
    "    - GLUE es el servicio de ETLs de AWS, GLUE puede leer la data, transformarla y limpiarla, creando tablas que sirven como metadata para saber donde se encuentra organizada la información en S3. Con lo cual para este proceso, extrae la información de S3, la procesa, y vuelve a dejarla ya transformada en otro bucket distinto nuevamente en S3. \n",
    "    \n",
    "5. En definitiva GLUE crea un catálogo que permite a Athena, realizar consultas SQL sobre data estructurada y NO estructurada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44c5d42",
   "metadata": {},
   "source": [
    "## <a name=\"mark_16\"></a> Casos de uso  \"S3\" - **Compliance**\n",
    "\n",
    "## [Indice](#index_01)\n",
    "\n",
    "![](img_74.png)\n",
    "\n",
    "### Logs a nivel de objetos\n",
    "\n",
    "Bucket conectado a Cloudtrail, para conectar CloudWatch y aquí hacemos el filtrado para que solamente nos reciba eventos de tipo PUT y DELETE mandando una notificación (SNS) al stakeholder.\n",
    "\n",
    "O podemos utilizar AWS Macie Dashboard, y generar tipos de alertas por acciones que pasen en nuestros buckets, integrandolo con el Level Object Logging y generar tipos de alerta. \n",
    "\n",
    "Podríamos utilizar cualquiera de estos dos flujos, creando alertas Preventivas o Predictivas.\n",
    "\n",
    "Alertas Predictivas, se identifica que un usuario \"siempre\" escribe en el bucket una cierta cantidad de información, con lo cual por ejemplo Macie puede inferir que dada la modificación de un tipo de comportamiento crea una Alerta si este comportamiento se modifica. También puede conectarse al bucket de S3 analizar toda la información determinar el tipo de objeto y clasificarlo.\n",
    "\n",
    "En el entorno de AWS, las alertas se pueden utilizar para notificar a los administradores de sistemas sobre problemas potenciales o inesperados. Las alertas pueden ser **preventivas** o **predictivas**.\n",
    "\n",
    "**Las alertas preventivas** se activan cuando se produce un evento que podría provocar un problema. Por ejemplo, una alerta preventiva podría activarse si el uso de la CPU de una instancia EC2 supera un umbral determinado. Esto permitiría a los administradores de sistemas tomar medidas para evitar que la instancia se ralentice o se bloquee.\n",
    "\n",
    "**Las alertas predictivas** se activan cuando se detecta una tendencia que podría provocar un problema. Por ejemplo, una alerta predictiva podría activarse si el uso de la CPU de una instancia EC2 aumenta gradualmente durante un período de tiempo. Esto permitiría a los administradores de sistemas tomar medidas para prepararse para el aumento del uso de la CPU, como aumentar el tamaño de la instancia o ajustar la configuración de la aplicación.\n",
    "\n",
    "**Ejemplos de alertas preventivas:**\n",
    "\n",
    "* Una alerta que se activa si el uso de la CPU de una instancia EC2 supera el 80%.\n",
    "* Una alerta que se activa si el tiempo de respuesta de una base de datos supera los 500 milisegundos.\n",
    "* Una alerta que se activa si el número de errores de una aplicación supera los 100 por hora.\n",
    "\n",
    "**Ejemplos de alertas predictivas:**\n",
    "\n",
    "* Una alerta que se activa si el uso de la CPU de una instancia EC2 aumenta un 10% cada hora.\n",
    "* Una alerta que se activa si el número de usuarios conectados a una aplicación aumenta un 20% cada día.\n",
    "* Una alerta que se activa si el tráfico de red a un servidor aumenta un 50% en comparación con el promedio.\n",
    "\n",
    "Las alertas pueden ser configuradas para enviar notificaciones por correo electrónico, SMS o mensajería instantánea. También se pueden configurar para desencadenar acciones automatizadas, como reiniciar una instancia EC2 o cambiar la configuración de una aplicación.\n",
    "\n",
    "Las alertas son una herramienta importante para la gestión de la seguridad y el rendimiento en AWS. Al configurar alertas preventivas y predictivas, los administradores de sistemas pueden identificar y resolver problemas antes de que causen interrupciones o daños."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4d78f9",
   "metadata": {},
   "source": [
    "## <a name=\"mark_17\"></a> Encriptación en S3 - Llaves administradas por AWS\n",
    "\n",
    "## [Indice](#index_01)\n",
    "\n",
    "![](img_75.png)\n",
    "\n",
    "En el entorno de AWS, **cifrar en el lado del servidor** (SSE) es un proceso en el que los datos se cifran antes de almacenarse en un servicio de AWS. AWS es responsable de administrar las claves de cifrado y descifrado.\n",
    "\n",
    "**Ejemplos de SSE en AWS:**\n",
    "\n",
    "* **Amazon S3 --> SSE-S3:** Todos los objetos nuevos cargados en un bucket de S3 se cifran automáticamente con SSE-S3, que utiliza claves administradas por AWS.\n",
    "\n",
    "    - AWS se encarga de generar las llaves.\n",
    "    - AWS se encarga de administrar las llaves.\n",
    "    - AWS se encarga de almacenamiento de las llaves.\n",
    "    - AWS se encarga de la rotación de las llaves.\n",
    "\n",
    "\n",
    "![](img_76.png)\n",
    "\n",
    "Sistema de sifrado utilizado **AES-256**, si buscamos donde se encuentran almacenadas las llaves, buscamos IAM --> Encription keys, se guardan con el formato \"aws/mi_servicio\n",
    "\n",
    "![](img_77.png)\n",
    "\n",
    "Cuando no queremos tener cargas administrativas sobre la gestión de las llaves de encriptación SSE-S3 es una solución.\n",
    "\n",
    "## <a name=\"mark_18\"></a> Encriptación en S3 - Llaves almacenadas en AWS creadas por el Usuario (KMS).\n",
    "\n",
    "## [Indice](#index_01)\n",
    "\n",
    "KMD: Key Management Service.\n",
    "\n",
    "![](img_78.png)\n",
    "\n",
    "Características:\n",
    "\n",
    "     1. Nosotros creamos las llaves en IAM, pero AWS la almacena.    \n",
    "     2. Podemos especificar quienes puede usar y/o administrar la llave (a nivel de usuarios o roles).\n",
    "\n",
    "![](img_79.png)\n",
    "\n",
    "Algunos casos de uso:\n",
    "\n",
    "_ Por ejemplo cuando estamos trabajando con diferentes ambientes Development, Staging, y Production, cada ambiente tiene su propia llave de encriptación.\n",
    "\n",
    "_ Los Buckets de igual forma son separados por ambientes y están encriptados con su llave de ambiente.\n",
    "\n",
    "_ Funciones \"lambda\" para encritptar variables de entorno.\n",
    "\n",
    "## <a name=\"mark_19\"></a> Encriptación en S3 - Llaves del Usuario - \"SSE-C\"\n",
    "\n",
    "## [Indice](#index_01)\n",
    "\n",
    "![](img_80.png)\n",
    "\n",
    "Lo que este flujo nos muestra es lo siguiente --> El usuario genera las llaves en su propio sistema para proveerlas a S3 para encriptar la data y luego guardarla en S3.\n",
    "\n",
    "Si es necesario descargar la información, el mismo usuario debe proveer la llave para realizarlo.\n",
    "\n",
    "El usuarion que esté usando S3 tiene total control de la llave.\n",
    "\n",
    "La información de la clave debe pasarse a travéz de los encabezados.\n",
    "\n",
    "![](img_81.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86d72e2",
   "metadata": {},
   "source": [
    "## <a name=\"mark_20\"></a> Laboratorio- crear llaves KMS y encriptación de objetos en S3\n",
    "\n",
    "## [Indice](#index_01)\n",
    "\n",
    "Vamos a IAM --> Encryption key\n",
    "\n",
    "![](img_85.png)\n",
    "\n",
    "## Observación_01: En la nueva versión de la consola AWS, ya no se crean por IAM si no por, Key Management Service (KMS)\n",
    "\n",
    "![](img_86.png)\n",
    "\n",
    "Creamos una nueva llave \"Create key\", colocamos el Alias y tendremos la posibilidad de crearla con \"KMS\" o \"External\" (importarla)\n",
    "\n",
    "![](img_87.png)\n",
    "\n",
    "Creamos las tags, estas tags nos permitiran a futuro crear reportes asociados por tags, para poder identificar recursos de un ambiente específico de un proyecto específico\n",
    "\n",
    "![](img_88.png)\n",
    "\n",
    "Primer medida de seguridad de KMS, aquí podremos especificar que usuarios y/o roles (podemos seleccionar más de uno) podrán utilizar la llave.\n",
    "\n",
    "![](img_89.png)\n",
    "\n",
    "Ahora necesitamos especificar que usuarios y/o roles pueden utilizar la llave para encriptar y desencriptar data.\n",
    "\n",
    "![](img_90.png)\n",
    "\n",
    "Creación y revisión de la política aplicada.\n",
    "\n",
    "![](img_91.png)\n",
    "\n",
    "Llave creada!!!\n",
    "\n",
    "![](img_92.png)\n",
    "\n",
    "![](img_93.png)\n",
    "\n",
    "## Observación_02: Las llaves son creadas por región, si elegimos una región diferente tendremos diferentes llaves.\n",
    "\n",
    "Ingresamos el bucket que recibirá la encriptación en S3.\n",
    "\n",
    "## Observación_03: El bucket y llave debe pertenecer a la misma región.\n",
    "\n",
    "![](img_82.png)\n",
    "\n",
    "![](img_83.png)\n",
    "\n",
    "En la etapa de \"Cifrado predeterminado\", SI DE AHORA EN ADELANTE copiamos objetos a nuestro bucket el sistema los encriptará con las opciones \"AES-256\" o \"AWS-KMS\" utilizando alguna de las llaves que le especifiquemos.\n",
    "\n",
    "Puede pasar que copiemos objetos encriptados con una llave completamente diferente, esos casos NO hay problemas de compatibilidad, pueden convivir en el mismo bucket objetos encriptados con diferentes llaves, ejemplo uno encriptadoso con SSE-S3 (AES-256) y otro con AWS-KMS\n",
    "\n",
    "![](img_84.png)\n",
    "\n",
    "Seleccionamos AWS-KMS y podremos ver nuestra llave.\n",
    "\n",
    "![](img_94.png)\n",
    "\n",
    "Guardamos y ya nos figura el cifrado predeterminado habilitado.\n",
    "\n",
    "![](img_95.png)\n",
    "\n",
    "Para verificar, solo cargamos un archivo al bucket, y en las propiedades del archivo podremos ver que está cifrado con AWS-KMS \"platzillave\", es importante destacar que en las propiedades del objeto podemos cambiar el tipo de encriptación a SSE-S3 o también cambiar la llave de encriptación de AWS-KMS\n",
    "\n",
    "![](img_96.png)\n",
    "\n",
    "## Importante: si alguna persona agena a nuestro bucket por algún motivo tiene acceso a nuestros objetos, no podrá ver la información ya que se encuentra encriptada.\n",
    "\n",
    "## <a name=\"mark_21\"></a> Encriptación Python lib Boto 3\n",
    "\n",
    "## [Indice](#index_01)\n",
    "\n",
    "Otras de las opciones que tenemos a nivel de encriptación es que podemos usar las SDK, con Python y la librería Boto 3, podemos copiar objetos a nuestro bucket realizando la encriptación.\n",
    "\n",
    "![](img_97.png)\n",
    "\n",
    "Debemos tener en cuenta el \"ServerSideEncryption\"\n",
    "\n",
    "![](img_98.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01837084",
   "metadata": {},
   "source": [
    "## <a name=\"mark_22\"></a> Introducción a Políticas en S3\n",
    "\n",
    "## [Indice](#index_01)\n",
    "\n",
    "Una política basicamente es un control de seguridad que nos permite controlar, que usuarios o que roles van a tener acceso a nuestro bucket y con que condiciones.\n",
    "\n",
    "![](img_99.png)\n",
    "\n",
    "![](img_100.png)\n",
    "\n",
    "Politicas de seguridad, se aplican sobre usuarios/roles y se describen en formato json.\n",
    "\n",
    "Ejemplo:\n",
    "```json\n",
    " {   \n",
    "     \"Version\":\"2012-10-17\",   \n",
    "     \"Statement\":[     \n",
    "         {\n",
    "         \"Sid\":\"PublicRead\",       \n",
    "         \"Effect\":\"Allow\",       \n",
    "         \"Principal\": \"*\",       \n",
    "         \"Action\":[\"s3:GetObject\"],       \n",
    "         \"Resource\":[\"arn:aws:s3:::examplebucket/*\"]     \n",
    "         }   \n",
    "    ] \n",
    "}\n",
    "```\n",
    "\n",
    "Atributos:\n",
    "\n",
    "    - Version: es opcional, por defecto toma la última version y determina el formato valido.\n",
    "\n",
    "    - Statement: es Obligatorio y es una lista de objetos json. cada Objeto en statement tendra el siguiente formato:\n",
    "    \n",
    "![](img_101.png)\n",
    "        \n",
    "- Sid: opcional, pero algunos servicios pueden solicitar este id\n",
    "- Effect : es obligatorio, valores: Allow o Deny\n",
    "- Principal: es obligatorio, es el arn del usuario o rol.\n",
    "\n",
    "## Estableciendo políticas\n",
    "\n",
    "Ingresamos a nuestro bucket --> Permisos --> Politica del Bucket\n",
    "\n",
    "![](img_102.png)\n",
    "\n",
    "![](img_103.png)\n",
    "\n",
    "Click en \"generador de politicas\"\n",
    "\n",
    "![](img_104.png)\n",
    "\n",
    "En \"principal\" **usamos el ARN (Amazon Resource Name) de un usuario**, para eso vamos a IAM --> users, ingresamos al usuario y copiamos su ARN\n",
    "\n",
    "![](img_105.png)\n",
    "\n",
    "El \"Amazon Resource Name (ARN)\", **va a ser del bucket en el cual vamos a generar la política**, ingresar a S3 --> el bucket a utilizar.\n",
    "\n",
    "![](img_106.png)\n",
    "\n",
    "Ahora ya tengo todos los parámetros, las \"Acciones\" serán los permisos para realizar acciones dentro del bucket.\n",
    "\n",
    "![](img_107.png)\n",
    "\n",
    "Finalmente hacemos click en \"Add Statement\" --> \"Generate Policy\"\n",
    "\n",
    "![](img_108.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eec7b68",
   "metadata": {},
   "source": [
    "## <a name=\"mark_23\"></a> Ejemplos de Políticas en S3\n",
    "\n",
    "## [Indice](#index_01)\n",
    "\n",
    "En el siguinte ejemplo la política permite, que todos los usuarios `\"Principal\":\"*\"`, obtengan objetos de S3, del todas las subcarpetas del bucket \"examplebucket\"\n",
    "\n",
    "![](img_109.png)\n",
    "\n",
    "Siguiente ejemplo, permite a dos usuarios (con cuentas distintas, pueden no pertenecer a la cuenta del bucket), poner objetos en todas las subcarpetas del bucket, cuando se cumpla la condición en \"condition\".\n",
    "\n",
    "![](img_110.png)\n",
    "\n",
    "Siguiente ejemplo, permitir a todos los usuarios todas las acciones en S3 en todas las subcarpetas del bucket, solo cuando se cumpla la condición --> IP de origen debe ser 54.240.143.0/24 y no 54.240.143.188/32\n",
    "\n",
    "![](img_111.png)\n",
    "\n",
    "Siguiente ejemplo, permitir a todos los usuarios obtener objetos en todas las subcarpetas del bucket, solo cuando se cumpla la condición \"las consultas deben provenir de los sitios web especificados.\n",
    "\n",
    "![](img_112.png)\n",
    "\n",
    "Siguiente ejemplo, permitir a todos los usuarios obtener objetos en todas las subcarpetas del bucket, solo cuando se cumpla la condición \"las consultas deben provenir de los sitios web especificados. Y que todo lo que no venga de los sitios mencionados, no lo permita\n",
    "\n",
    "![](img_113.png)\n",
    "\n",
    "Siguiente ejemplo, denegar a todos los usuarios todas las acciones hacia todos los objetos dentro de la subcarpeta \"taxdocuments\", que no tenga \"MultiFactorAuthAge\". A su vez todos los usarios tienen permitido un GetObject de todos los objetos del bucket, esto no incluye la carpeta antes mencionada.\n",
    "\n",
    "Null al principio, quiere decir que si el MultiFactorAuthAge no existe entonces va a denegar el acceso, debe tener el Multifacto Authentication activo en la cuenta para poder acceder al bucket.\n",
    "\n",
    "![](img_114.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e698097a",
   "metadata": {},
   "source": [
    "## <a name=\"mark_24\"></a> ACL (Access Control List) en S3\n",
    "\n",
    "## [Indice](#index_01)\n",
    "\n",
    "Son listas de control de acceso al bucket, y son una capa de seguridad extra, ACL permite que otras cuentas tengan permisos sobre un bucket que especifiquemos. Podemos hacer dministración de permisos a nivel de cuentas o a nivel de grupos de usuarios autenticados.\n",
    "\n",
    "ACL (damos permiso a usuario) --> Política (que le permitimos hacer)\n",
    "\n",
    "![](img_115.png)\n",
    "\n",
    "Ingresando a nuestro bucket, \"permisos\" --> \"listas de control de acceso\"\n",
    "\n",
    "![](img_116.png)\n",
    "\n",
    "Podemos permitir el acceso colocando el id de la otra cuenta o el email (no todas las regiones permiten el ingreso de email)\n",
    "\n",
    "![](img_117.png)\n",
    "\n",
    "## NO RECOMENDADO!!!\n",
    "\n",
    "También podemos configara el bucket para que tenga acceso público, esto generará una tag en el bucket como \"publico\". \n",
    "\n",
    "![](img_118.png)\n",
    "\n",
    "El grupo envío de registros de S3, nos permite obtener un registro de actividades sobre los buckets, para saber que están haciendo las cuentas sobre nuestro bucket.\n",
    "\n",
    "![](img_118.png)\n",
    "\n",
    "Lectura recomendada: https://docs.aws.amazon.com/es_es/AmazonS3/latest/dev/acl-overview.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42934ca7",
   "metadata": {},
   "source": [
    "## <a name=\"mark_25\"></a> Storage Gateway\n",
    "\n",
    "## [Indice](#index_01)\n",
    "\n",
    "Es el servicio que conecta \"On Premise\" con la \"Nube\", nos permite aprovechar los beneficios en la nube para infraestructuras y arquitecturas implementadas On Premise\n",
    "\n",
    "Tapes: Cintas de Back-Up\n",
    "\n",
    "![](img_120.png)\n",
    "\n",
    "Protocolos: Son los protocolos utilizados por Storage Gateway para conectar on premise con la nube.\n",
    "\n",
    "![](img_121.png)\n",
    "\n",
    "![](img_122.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a314775",
   "metadata": {},
   "source": [
    "## <a name=\"mark_26\"></a> File Gateway\n",
    "\n",
    "## [Indice](#index_01)\n",
    "\n",
    "File Gateway es uno de los tipos de storages, donde podemos pasar nuestros objetos a S3, nuestros logs de procesamiento, a nivel de objetos.\n",
    "\n",
    "![](img_123.png)\n",
    "\n",
    "Por ejemplo, si por cuestiones de latencia queremos mantener ciertos objetos on premise mientras se realiza la migración, este tipo de storage provee una opción que se llama \"cache\", con lo cual podríamos hacer un cache de esto objetos de forma local mientras se van replicando hacia la nube.\n",
    "\n",
    "![](img_124.png)\n",
    "\n",
    "Vamos a la consola de AWS y buscamos Storage Gateway.\n",
    "\n",
    "![](img_125.png)\n",
    "\n",
    "![](img_126.png)\n",
    "\n",
    "Compatibilidad de File Gateway, aquí podremos bajas las diferentes imagenes que nos permitiran instalarlas en nuestro datacenter, VMware, Hyper-V, crear una instancia EC2, o a travéz de hardware. Para este caso se uso la imagen de VMware ESXi.\n",
    "\n",
    "![](img_127.png)\n",
    "\n",
    "![](img_128.png)\n",
    "\n",
    "Material complementario --> https://www.youtube.com/watch?v=83Wa4RJuMwo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfc069f",
   "metadata": {},
   "source": [
    "## <a name=\"mark_27\"></a> VTL - Virtual Tape Library -Tape Gateway\n",
    "## [Indice](#index_01)\n",
    "\n",
    "Cómo vamos a conectar las cintas de back-up on-premise con la nube, esto es una VM que tiene integraciones con los principales fabricantes que se dedican a proveer cintas\n",
    "\n",
    "![](img_129.png)\n",
    "\n",
    "Nuevamente en Storage Gateway podemos encontrar Tape Gateway\n",
    "\n",
    "![](img_130.png)\n",
    "\n",
    "![](img_127.png)\n",
    "\n",
    "![](img_128.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9fa98e",
   "metadata": {},
   "source": [
    "## <a name=\"mark_28\"></a> Volume Gateway\n",
    "## [Indice](#index_01)\n",
    "\n",
    "También maneja un cache a nivel de archivos locales, para mejorar la latencia.\n",
    "\n",
    "![](img_131.png)\n",
    "\n",
    "Los Snapshot cargados asincronamente en AWS pueden volverse EBS \n",
    "\n",
    "![](img_132.png)\n",
    "\n",
    "En Storage Gateway podemos encontrar \"Volume gateway\", podemos crear Volumenes de Cache o Stored Volumes donde podemos tener schedules para cargar nuestros back ups o snapshots a AWS.\n",
    "\n",
    "![](img_133.png)\n",
    "\n",
    "Notar que si elegimos \"Stored Volume\", como vamos a migrar volumenes, requerimos una VM On-Premise y no hay opción de EC2\n",
    "\n",
    "![](img_134.png)\n",
    "\n",
    "![](img_128.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ed877a",
   "metadata": {},
   "source": [
    "## <a name=\"mark_29\"></a> Elastic File System\n",
    "## [Indice](#index_01)\n",
    "\n",
    "Es un sistema de archivos, muchas veces en AWS tenemos diferentes tipos de servidores y queremos que estos servidores se conecten a un mismo almacenamiento, si intentamos realizar eso con S3 probablemente no sea la mejor opción, en la medida que no podemos dejar a S3 como una unidad dentro del sistema operativo. Aquí podemos usar EFS, que tiene un endpoint al cual se pueden conectar una gran cantidad de instancias.\n",
    "\n",
    "En el siguiente ejemplo vemos 2 instancias diferentes que pueden estar en zonas diferentes dentro de la misma región, conectadas/montadas al mismo EFS\n",
    "\n",
    "![](img_135.png)\n",
    "\n",
    "![](img_136.png)\n",
    "\n",
    "Este tipo de almacenamiento versus S3, es el más costoso, pero el pricing irá creciendo solo a medida que utilicemos el servicio.\n",
    "\n",
    "Para el punto de \"Funcionalidad\", solo permite el acceso a instancias basadas en linux.\n",
    "\n",
    "![](img_137.png)\n",
    "\n",
    "_ IOPS (Input Output Per Second): Se deben establecer a E/S Max (Escritura y Lectura más rápido). Para tener una mejor respuesta ante las peticiones de los archivos alojado en el EFS.\n",
    "\n",
    "_ Uso General: No es rapido, es decir, no es más rapido que un EBS por el contrario es mucho menor, lo defino como normal y aceptable de acuerdo con la necesidad IO que tengas sobre este disco.\n",
    "\n",
    "Sobre la configuración de RED:\n",
    "\n",
    "_ Transmisión por Ráfagas (rafagas de tráfico): es bueno pero tiene un gran problema en mi concepto... Este se basa en creditos, que no son muy claros al rastrearse.... y si tienes un trafico basico o pequeño, es funcional pero si tus accesos o procesamiento de IOPS aumenta por cualquier razón, te consumes los creditos y rendimiento comienza frenarse poco a poco y no te notifica, hasta que queda extremadamente lento, hasta que se renuevan los creditos...\n",
    "\n",
    "_ Aprovisionado: Es lo mejor, es de calcular la tasa IOPS y es super bueno. Al ser un EFS la velocidad va a estar dada por la red y si tenemos instancias en diferentes zonas de disponibilidad, la red y la latencia va a ser un factor muy importante.\n",
    "\n",
    "Funcionalidad: Ya cuenta con una integración a KMS\n",
    "\n",
    "![](img_138.png)\n",
    "\n",
    "EFS no tiene compatibilidad con el sistema operativo Windows. EFS solo es compatible con los siguientes sistemas operativos:\n",
    "\n",
    "* **Amazon Linux 2**\n",
    "* **Ubuntu 16.04 LTS**\n",
    "* **Ubuntu 18.04 LTS**\n",
    "* **Ubuntu 20.04 LTS**\n",
    "* **Red Hat Enterprise Linux 7.6**\n",
    "* **Red Hat Enterprise Linux 8**\n",
    "* **CentOS 7.6**\n",
    "* **CentOS 8**\n",
    "* **SUSE Linux Enterprise Server 12 SP4**\n",
    "* **SUSE Linux Enterprise Server 15**\n",
    "\n",
    "Para utilizar EFS con Windows, puede utilizar un cliente de terceros como Amazon FSx for Windows File Server. Amazon FSx for Windows File Server es un servicio de almacenamiento de archivos administrado que proporciona una experiencia de almacenamiento de archivos de Windows compatible con el estándar NTFS.\n",
    "\n",
    "Si necesita utilizar EFS con Windows, puede utilizar una de las siguientes soluciones:\n",
    "\n",
    "* **Utilizar un cliente de terceros como Amazon FSx for Windows File Server.**\n",
    "* **Utilizar una máquina virtual con un sistema operativo compatible con EFS.**\n",
    "* **Utilizar un contenedor con un sistema operativo compatible con EFS.**\n",
    "\n",
    "Ingresamos a EFS en AWS --> Crear un sistema de archivos. Lo primero es que nos va pedir que selecciones la VPC en la cual vamos a desplegar EFS.\n",
    "\n",
    "![](img_139.png)\n",
    "\n",
    "Y las zonas de disponibilidad las cuales va a ver este EFS.\n",
    "\n",
    "![](img_140.png)\n",
    "\n",
    "![](img_141.png)\n",
    "\n",
    "![](img_142.png)\n",
    "\n",
    "![](img_143.png)\n",
    "\n",
    "![](img_144.png)\n",
    "\n",
    "![](img_145.png)\n",
    "\n",
    "![](img_146.png)\n",
    "\n",
    "Podemos seleccionar la llave KMS o podemos elegir el ARN de la clave de KMS en otra cuenta.\n",
    "\n",
    "![](img_147.png)\n",
    "\n",
    "y damos click en \"Crear un sistema de archivos\", una vez terminado el proceso, se nos provee de un endpoint de conexión, todas las instrucciones de montaje del endpoint y de mantenerlo persistente a pesar de reinicio\n",
    "\n",
    "![](img_148.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756c4bc6",
   "metadata": {},
   "source": [
    "## <a name=\"mark_30\"></a> Casos de uso de EFS\n",
    "## [Indice](#index_02)\n",
    "\n",
    "En el siguiente ejemplo tenemos un sitio web (representado por Amazon EC2), el cual irá creciendo automaticamente con la demanda, desplegando automaticamente más instancias a mayor demanda. Para estos casos se configura la plantilla para que todas las instancias que se van creando puedan leer el mismo EFS y todas tengan la misma fuente de información.\n",
    "\n",
    "En forma paralela está conectada a un S3 donde se guarda la imagen que utilizaran todas las instancias.\n",
    "\n",
    "![](img_149.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00ec37c",
   "metadata": {},
   "source": [
    "## <a name=\"mark_31\"></a> Características de Elastic Block Storage\n",
    "## [Indice](#index_02)\n",
    "\n",
    "Elastic Block Storage es un servicio de almacenamiento basado en bloques; y al ser basado en bloques, nos va a brindar dos características que no tenemos en otros sistemas de archivos: podemos instalar sistemas operativos y podemos instalar aplicaciones. Este tipo de almacenamiento lo podemos ver como un disco duro virtual en la nube.\n",
    "\n",
    "### Características\n",
    "\n",
    "Podemos adherirlo a una instancia. \n",
    "\n",
    "![](img_150.png)\n",
    "\n",
    "Sin embargo, a diferencia de EFS, en este servicio se paga por almacenamiento aprovisionado, y esto es porque como se utiliza como almacenamiento de sistemas operativos, no puede ser dinámico.\n",
    "\n",
    "Si se desea cambiar el tamaño del almacenamiento del disco, en Linux se realiza el cambio a través de la terminal; y en caso de utilizar Windows Server, se debe primero realizar el cambio en la consola de AWS y luego en la administración de discos dentro del servidor. \n",
    "\n",
    "Aunque se recomienda siempre aprovisionar desde el comienzo el tamaño de almacenamiento necesario para evitar tener que redimencionarlo, debido a que puede ser peligroso para la información.\n",
    "\n",
    "Replicación: Cada volumen se replica dentro de una AZ (zona de disponibilidad) para proteger ante un error.\n",
    "\n",
    "Diseño: Está diseñado para ayudar a diferentes cargas de trabajo (poca lectura y escritura hasta alta lectura y escritura).\n",
    "\n",
    "Montaje: Un EBS puede estar asociado sólo a una instancia EC2, y una instancia EC2 puede estar asociada a varios EBS.\n",
    "\n",
    "![](img_151.png)\n",
    "\n",
    "Boot: Una de las versiones de EBS puede ser el Boot de una instancia, el que tiene el sistema operativo instalado Windows o Linux, este sistema raiz NO puede ser encriptado, cuando uno está creando la instancia se puede elegir el volumen y habilitar o deshabilitar la encriptación, pero NO para volumenes raíz, que tienen sistema operativo, solo para volumenes externos.\n",
    "\n",
    "Volumen adicional: Pueden encriptarse y usar todos los tipos de EBS disponibles.\n",
    "\n",
    "Montaje: Se puede hacer por la CLI, SDK, o Consola de AWS y a nivel de sistema operativo.\n",
    "\n",
    "![](img_152.png)\n",
    "\n",
    "Tipos: Hay diferentes tipos de EBS.\n",
    "\n",
    "Protección: Se puede proteger el borrado accidental al crear la instancia.\n",
    "\n",
    "Límites: Pueden ser de hasta 16TB. El almacenamiento origen (con que tamaño se inicia) varía según el tipo de EBS.\n",
    "\n",
    "![](img_153.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc562da",
   "metadata": {},
   "source": [
    "## <a name=\"mark_32\"></a> Tipos de EBS - GP2 - IO1\n",
    "## [Indice](#index_02)\n",
    "\n",
    "Lo primero a tener en cuenta es que son SSD (Discos de estado sólido).\n",
    "\n",
    "### GP2\n",
    "\n",
    "GP2: General Purpose, cargas std sin picos de consumo (si instalamos una DDBB en EC2 con un consumo regular) .\n",
    "\n",
    "![](img_154.png)\n",
    "\n",
    "### IO1\n",
    "\n",
    "![](img_155.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84dde22",
   "metadata": {},
   "source": [
    "## <a name=\"mark_33\"></a> Tipos de EBS - ST1 - SC1\n",
    "## [Indice](#index_02)\n",
    "\n",
    "Estos son HDD, Hard Disk Drive (unidad de disco duro).\n",
    "\n",
    "### ST1\n",
    "\n",
    "![](img_156.png)\n",
    "\n",
    "### SC1\n",
    "\n",
    "Por capacidad aprovicionada.\n",
    "\n",
    "![](img_157.png)\n",
    "\n",
    "## Observación_01:\n",
    "\n",
    "Al crear la instancia EC2, en el 4to paso podemos elegir el tipo de volumen, hay un 3er tipo \"Magnetic (Standard)\", no recomendado ya que este volumen es el almacenamiento local utilizado por el Hipervisor para lanzar la VM, NO garantiza que la información que guardamos sea persistente.\n",
    "\n",
    "![](img_158.png)\n",
    "\n",
    "Si agregamos otros volumenes, se habilita más volumes.\n",
    "\n",
    "![](img_159.png)\n",
    "\n",
    "En el contexto de AWS, **IOPS** y **throughput** son dos medidas del rendimiento del almacenamiento.\n",
    "\n",
    "**IOPS** significa **operaciones de entrada/salida por segundo**. Mide la cantidad de operaciones de lectura o escritura que un dispositivo de almacenamiento puede realizar por segundo. Las operaciones de entrada/salida pueden incluir leer o escribir un archivo, crear o eliminar un archivo, o abrir o cerrar un archivo.\n",
    "\n",
    "**Throughput** significa **tasa de transferencia de datos**. Mide la cantidad de datos que un dispositivo de almacenamiento puede transferir por segundo. El throughput se mide en bytes por segundo.\n",
    "\n",
    "En general, las aplicaciones que requieren un acceso aleatorio a los datos, como las bases de datos, necesitan un rendimiento alto en IOPS. Las aplicaciones que requieren un acceso secuencial a los datos, como las aplicaciones de streaming de video, necesitan un rendimiento alto en throughput.\n",
    "\n",
    "En AWS, los servicios de almacenamiento ofrecen diferentes niveles de rendimiento en IOPS y throughput. El nivel de rendimiento que necesita una aplicación depende de sus requisitos específicos.\n",
    "\n",
    "**A continuación se muestra una tabla que resume las principales diferencias entre IOPS y throughput:**\n",
    "\n",
    "| Característica | IOPS | Throughput |\n",
    "|---|---|---|\n",
    "| Definición | Operaciones de entrada/salida por segundo | Tasa de transferencia de datos |\n",
    "| Medida | Operaciones por segundo | Bytes por segundo |\n",
    "| Aplicación | Acceso aleatorio | Acceso secuencial |\n",
    "\n",
    "**Ejemplos:**\n",
    "\n",
    "* Una base de datos que necesita responder rápidamente a consultas de búsqueda necesitará un alto rendimiento en IOPS.\n",
    "* Una aplicación de streaming de video que necesita transferir grandes cantidades de datos rápidamente necesitará un alto rendimiento en throughput.\n",
    "\n",
    "**Recomendaciones:**\n",
    "\n",
    "* Para determinar el nivel de rendimiento que necesita una aplicación, debe medir la carga de trabajo de la aplicación. Puede usar herramientas de monitoreo para recopilar datos sobre el uso del almacenamiento de la aplicación.\n",
    "* Una vez que haya medido la carga de trabajo de la aplicación, puede usar las especificaciones de rendimiento de los servicios de almacenamiento de AWS para seleccionar el nivel de rendimiento adecuado.\n",
    "\n",
    "## Observación_02:\n",
    "\n",
    "También podemos primero crear el volumen y luego attachar la instancia. En el dashboard, seleccionamos el volumen, Action --> Attach Volume\n",
    "\n",
    "![](img_160.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71563812",
   "metadata": {},
   "source": [
    "## <a name=\"mark_34\"></a> Snapshots y AMI\n",
    "## [Indice](#index_02)\n",
    "\n",
    "Snapshot: Copia de seguridad del volumen, en un instante de tiempo.\n",
    "\n",
    "Un **snapshot** es una copia de los datos de un sistema, como una máquina virtual, un volumen de almacenamiento o una base de datos. Los snapshots se crean de forma instantánea, lo que significa que capturan el estado de los datos en un momento determinado.\n",
    "\n",
    "**Características de un snapshot:**\n",
    "\n",
    "* Es una copia de los datos en un momento determinado.\n",
    "* Se crea de forma instantánea.\n",
    "* Es una copia de solo lectura.\n",
    "* Se almacena en el mismo sistema de almacenamiento que los datos originales.\n",
    "\n",
    "**Diferencias entre un snapshot y un backup:**\n",
    "\n",
    "| Característica | Snapshot | Backup |\n",
    "|---|---|---|\n",
    "| **Cuándo se crea** | Instantáneamente | Programadamente |\n",
    "| **Estado de los datos** | En el momento de la creación | En un momento específico |\n",
    "| **Modo de lectura** | Solo lectura | Lectura y escritura |\n",
    "| **Ubicación de almacenamiento** | Mismo sistema de almacenamiento | Sistema de almacenamiento independiente |\n",
    "\n",
    "**Usos de los snapshots:**\n",
    "\n",
    "* **Prueba y desarrollo:** Los snapshots se pueden utilizar para crear entornos de prueba y desarrollo que sean idénticos a los entornos de producción.\n",
    "* **Recuperación ante desastres:** Los snapshots se pueden utilizar para restaurar los datos en caso de un desastre, como una pérdida de datos o una interrupción del sistema.\n",
    "* **Control de versiones:** Los snapshots se pueden utilizar para conservar versiones anteriores de los datos.\n",
    "\n",
    "**Recomendaciones:**\n",
    "\n",
    "* Los snapshots se deben crear con regularidad para garantizar que se disponga de una copia de los datos en caso de que se pierdan o se corrompan.\n",
    "* Los snapshots se deben almacenar en un sistema de almacenamiento seguro para evitar que sean modificados o eliminados accidentalmente.\n",
    "\n",
    "**Conclusiones:**\n",
    "\n",
    "En términos de datos, un snapshot y un backup son copias de los datos que se pueden utilizar para restaurar los datos en caso de pérdida o corrupción. Sin embargo, existen algunas diferencias importantes entre los dos, como el momento en que se crean, el estado de los datos y la ubicación de almacenamiento.\n",
    "\n",
    "![](img_161.png)\n",
    "\n",
    "### Característica incremental del Snapshot.\n",
    "\n",
    "![](img_162.png)\n",
    "\n",
    "En EC2 vamos a la parte de volúmenes, seleccionamos el volumen, Actions --> Create Snapshot\n",
    "\n",
    "![](img_163.png)\n",
    "\n",
    "El Snapshot no está encriptado porque el volumen no está encriptado, en consecuencia se el volumen fue encriptado el Snapshot también lo estará.\n",
    "\n",
    "![](img_164.png)\n",
    "\n",
    "### Life Cycle\n",
    "\n",
    "![](img_165.png)\n",
    "\n",
    "Las reglas son creadas a nivel de tags, con lo cual del total de EBS que tengamos, el snapshot solo será aplicado a aquellos que tengan el tag correspondiente.\n",
    "\n",
    "![](img_166.png)\n",
    "\n",
    "![](img_167.png)\n",
    "\n",
    "Especificamos un role que tenga los permisos necesarios para ejecutar los snapshot, habilitamos y creamos la poítica.\n",
    "\n",
    "![](img_168.png)\n",
    "\n",
    "### Observación_01: \n",
    "\n",
    "Los snapshots también pueden ser utilizados para crear otras máquinas con la característica especial de un snapshot determinado.\n",
    "\n",
    "## AMI\n",
    "\n",
    "![](img_169.png)\n",
    "\n",
    "En el contexto de AWS, una AMI (Imagen de máquina de Amazon) es una instantánea de un sistema operativo y sus componentes, como los archivos del sistema, los archivos de configuración y los paquetes instalados. Las AMI se pueden utilizar para crear instancias de EC2, que son máquinas virtuales que se ejecutan en la nube de AWS.\n",
    "\n",
    "**Características de una AMI:**\n",
    "\n",
    "* **Es una copia de un sistema operativo y sus componentes.**\n",
    "* Se puede utilizar para crear instancias de EC2.\n",
    "* Se puede almacenar en el repositorio de imágenes de AWS.\n",
    "* Se puede compartir con otros usuarios.\n",
    "\n",
    "**Usos de una AMI:**\n",
    "\n",
    "* **Lanzamiento de instancias:** Las AMI se pueden utilizar para lanzar instancias de EC2. Esto permite a los usuarios crear máquinas virtuales con un sistema operativo y sus componentes ya instalados.\n",
    "* **Prueba y desarrollo:** Las AMI se pueden utilizar para crear entornos de prueba y desarrollo. Esto permite a los usuarios probar aplicaciones y servicios en un entorno controlado.\n",
    "* **Recuperación ante desastres:** Las AMI se pueden utilizar para restaurar instancias en caso de un desastre. Esto permite a los usuarios recuperar rápidamente su infraestructura en caso de una interrupción del sistema.\n",
    "* **Actualización de sistemas operativos:** Las AMI se pueden utilizar para actualizar sistemas operativos. Esto permite a los usuarios actualizar sus instancias de EC2 a la última versión del sistema operativo sin tener que reinstalar el sistema operativo manualmente.\n",
    "\n",
    "**Recomendaciones:**\n",
    "\n",
    "* Las AMI se deben crear con regularidad para garantizar que se disponga de una copia del sistema operativo en caso de que se pierda o se corrompa.\n",
    "* Las AMI se deben almacenar en un repositorio seguro para evitar que sean modificadas o eliminadas accidentalmente.\n",
    "\n",
    "**Conclusiones:**\n",
    "\n",
    "Las AMI son una herramienta importante para la administración de sistemas en AWS. Son fáciles de crear y utilizar, y pueden utilizarse para una variedad de propósitos.\n",
    "\n",
    "### Observación_02: \n",
    "No debe confundirse un Snapshot (es como un back-up), y una AMI (es un template de conf. del Sistema Operativo), al momento de una recuperación, un snapshot contiene la estructura del Sistema Operativo + Aplicaciones + Datos, una AMI solo contiene la estructura del Sistema Operativo (puede incluir aplicaciones)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96e592e",
   "metadata": {},
   "source": [
    "## <a name=\"mark_35\"></a> Creación de EBS + integración con EC2 para Windows\n",
    "## [Indice](#index_02)\n",
    "\n",
    "Vamos a EC2 y creamos una instacia tipo Windows.\n",
    "\n",
    "![](img_170.png)\n",
    "\n",
    "Seleccionamos un tamaño grande para evitar problemas.\n",
    "\n",
    "![](img_171.png)\n",
    "\n",
    "Paso 3, lo dejamos tal cual como está.\n",
    "\n",
    "Paso 4, elgimos 2 volumenes \"General Purpose\", uno de ellos será el Root.\n",
    "\n",
    "![](img_172.png)\n",
    "\n",
    "![](img_173.png)\n",
    "\n",
    "Vamos a permitir el puerto RDP desde nuestra IP, y creamos el grupo de seguridad \n",
    "\n",
    "![](img_174.png)\n",
    "\n",
    "\"Launch\" la instancia, creamos la llave, la descargamos la llave (.pem) --> \"Launch Instance\"\n",
    "\n",
    "![](img_175.png)\n",
    "\n",
    "Una vez creada la instancia, la seleccionamos y creamos el password de administrador.\n",
    "\n",
    "![](img_176.png)\n",
    "\n",
    "![](img_177.png)\n",
    "\n",
    "![](img_178.png)\n",
    "\n",
    "Copiamos el password para realizar la conexión vía RDP al servidor.\n",
    "\n",
    "Levantamos la EC2 creada en nuestro local.\n",
    "\n",
    "![](img_179.png)\n",
    "\n",
    "Ingresamos a \"Server Manager\"\n",
    "\n",
    "![](img_180.png)\n",
    "\n",
    "![](img_181.png)\n",
    "\n",
    "![](img_182.png)\n",
    "\n",
    "Vamos a buscar el segundo volumen EBS.\n",
    "\n",
    "![](img_183.png)\n",
    "\n",
    "![](img_184.png)\n",
    "\n",
    "![](img_185.png)\n",
    "\n",
    "![](img_186.png)\n",
    "\n",
    "Disco online\n",
    "\n",
    "![](img_187.png)\n",
    "\n",
    "Con el disco online, ya podemos crear el nuevo volumen.\n",
    "\n",
    "![](img_188.png)\n",
    "\n",
    "![](img_189.png)\n",
    "\n",
    "![](img_190.png)\n",
    "\n",
    "![](img_191.png)\n",
    "\n",
    "![](img_192.png)\n",
    "\n",
    "![](img_193.png)\n",
    "\n",
    "![](img_194.png)\n",
    "\n",
    "![](img_195.png)\n",
    "\n",
    "![](img_196.png)\n",
    "\n",
    "Ya se encuentra el volumen visible y listo para usar.\n",
    "\n",
    "![](img_197.png)\n",
    "\n",
    "### Aumentando el tamaño de un volumen existente.\n",
    "\n",
    "Ingresamos en volumenes AWS, seleccionamos el volumen --> Action --> Modify Volume\n",
    "\n",
    "![](img_198.png)\n",
    "\n",
    "Aumentamos el tamaño a 200 GB\n",
    "\n",
    "![](img_199.png)\n",
    "\n",
    "![](img_200.png)\n",
    "\n",
    "Ahora tenemos que aplicar el cambio a nivel de sistema operativo, ingresamos a la instancia EC2\n",
    "\n",
    "![](img_201.png)\n",
    "\n",
    "![](img_202.png)\n",
    "\n",
    "![](img_203.png)\n",
    "\n",
    "![](img_204.png)\n",
    "\n",
    "### Observación_01: Es importante aprovisionar correctamente nuestro discos para evitar este trabajo de redimensionamiento, otro cosa, NO se puede decrementar el tamaño de un volúmen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefb2aec",
   "metadata": {},
   "source": [
    "## <a name=\"mark_36\"></a> Creación de EBS + integración con EC2 para Linux\n",
    "## [Indice](#index_02)\n",
    "\n",
    "Vamos a EC2 y creamos una instancia con Linux.\n",
    "\n",
    "![](img_205.png)\n",
    "\n",
    "![](img_206.png)\n",
    "\n",
    "Step 3 queda como está.\n",
    "\n",
    "![](img_207.png)\n",
    "\n",
    "![](img_208.png)\n",
    "\n",
    "![](img_209.png)\n",
    "\n",
    "![](img_210.png)\n",
    "\n",
    "Una vez creada la instancia, copiamos la ip publica.\n",
    "\n",
    "![](img_211.png)\n",
    "\n",
    "Para la conexión utilizamos \"MobaXterm\"\n",
    "\n",
    "![](img_212.png)\n",
    "\n",
    "![](img_213.png)\n",
    "\n",
    "Y nos conectamos a nuestra instancia.\n",
    "\n",
    "![](img_214.png)\n",
    "\n",
    "lsblk = revisamos volumenes montados, donde vemos nuestro root de 20GB y el segundo volumen de 35GB\n",
    "\n",
    "![](img_215.png)\n",
    "\n",
    "sudo mkfs -t ext4 /dev/xvdb = Este comando nos ayuda a dar formato (ext4) al volumen en \"/dev/xvdb\".\n",
    "\n",
    "![](img_216.png)\n",
    "\n",
    "sudo mkdir platzi = Creamos punto o directorio de montaje en el EBS root.\n",
    "\n",
    "![](img_217.png)\n",
    "\n",
    "sudo mount /dev/xvdb platzi --> Realizamos el montaje del volumen EBS al directorio \"platzi\" del EBS root.\n",
    "\n",
    "![](img_218.png)\n",
    "\n",
    "cd platzi = Aquí vamos al punto de montaje para poder escribir. Entonces todo lo que escribamos en el directorio \"platzi\" del EBS root, se replicará en el otro volumen EBS. \n",
    "\n",
    "Si como en el ejemplo con Windows, queremos aumentar la capacidad del volumen NO root, tendríamos que ir nuevamente al sistema operativo y hacer un re-zise FS a nivel de esa partición para que tome el tamaño adisional que agregamos en la consolo de AWS. Pero esto se puede hacer completamente a nivel de comando en Linux (también para Windows) son funcionalidades que provee EBS, podemos crecer los discos y tomar ventaja de todos los volumenes EBS con los que contamos.\n",
    "\n",
    "Nota: El best practice es que se pueda editar el archivo /etc/fstab para agregar una linea donde se agrega el punto de montaje y así quedara de manera persistente en el SO."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c7a4b7",
   "metadata": {},
   "source": [
    "## <a name=\"mark_37\"></a> AWS Storage \"S3\" vs \"EBS\" vs \"EFS\", Cuándo usar cada uno\n",
    "## [Indice](#index_02)\n",
    "\n",
    "S3/ EFS almacenamiento de Objetos: Imagenes, videos, documentos, archivos. NO podemos instalar aplicaciones.\n",
    "\n",
    "EBS almacenamiento por bloques: Podemos instalar aplicaciones, Sistema Operativo.\n",
    "\n",
    "El escalamiento (re-size) en EBS, como ya vimos hay que ingresar a nivel de sist. op. para que sea reconocido.\n",
    "\n",
    "NACL: Listas de Control de Acceso a nivel de Red, porque estos van a estar asociadas a una instancia dentro de una VPC.\n",
    "\n",
    "El `*` --> En su versión Std.\n",
    "\n",
    "![](img_219.png)\n",
    "\n",
    "Contenido Estático --> Sitios Web estáticos.\n",
    "\n",
    "![](img_220.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd00e164",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_kernel_01",
   "language": "python",
   "name": "data_trans_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
